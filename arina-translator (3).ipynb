{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46450f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:03:07.613983Z",
     "iopub.status.busy": "2025-03-11T14:03:07.613672Z",
     "iopub.status.idle": "2025-03-11T14:05:44.171929Z",
     "shell.execute_reply": "2025-03-11T14:05:44.170785Z",
     "shell.execute_reply.started": "2025-03-11T14:03:07.613953Z"
    },
    "papermill": {
     "duration": 160.932406,
     "end_time": "2025-03-09T19:37:53.869020",
     "exception": false,
     "start_time": "2025-03-09T19:35:12.936614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.3.0\n",
      "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchtext==0.18.0\n",
      "  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.3.0 (from torch==2.3.0)\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchtext==0.18.0) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext==0.18.0) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchtext==0.18.0) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchtext==0.18.0) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchtext==0.18.0) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchtext==0.18.0) (2024.2.0)\n",
      "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/da/d3/8057f0587683ed2fcd4dbfbdfdfa807b9160b809976099d36b8f60d08f03/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\u001b[0m\u001b[33m\n",
      "\u001b[0mDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
      "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
      "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n",
      "    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 24.12.1 which is incompatible.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\n",
      "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchtext-0.18.0 triton-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.3.0 torchtext==0.18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ca9fa",
   "metadata": {
    "papermill": {
     "duration": 0.049521,
     "end_time": "2025-03-09T19:37:53.966618",
     "exception": false,
     "start_time": "2025-03-09T19:37:53.917097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑÑŒ ĞºĞ¾Ğ´Ğ¾Ğ¼ Ğ¸Ğ·:\n",
    "https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n",
    "https://github.com/pytorch/examples/tree/main/language_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e7cdc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:44.173542Z",
     "iopub.status.busy": "2025-03-11T14:05:44.173254Z",
     "iopub.status.idle": "2025-03-11T14:05:47.998957Z",
     "shell.execute_reply": "2025-03-11T14:05:47.998229Z",
     "shell.execute_reply.started": "2025-03-11T14:05:44.173520Z"
    },
    "papermill": {
     "duration": 4.024441,
     "end_time": "2025-03-09T19:37:58.036915",
     "exception": false,
     "start_time": "2025-03-09T19:37:54.012474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/usr/local/lib/python3.10/dist-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/usr/local/lib/python3.10/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "#import sacrebleu\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5707d784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T19:37:58.130603Z",
     "iopub.status.busy": "2025-03-09T19:37:58.130304Z",
     "iopub.status.idle": "2025-03-09T19:37:58.808622Z",
     "shell.execute_reply": "2025-03-09T19:37:58.807357Z"
    },
    "papermill": {
     "duration": 0.726371,
     "end_time": "2025-03-09T19:37:58.810759",
     "exception": false,
     "start_time": "2025-03-09T19:37:58.084388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madromashkina\u001b[0m (\u001b[33madromashkina-hse\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"6ec916c1b5b8de7f9c11e7aff05f7f98c8166837\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef7e3b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T19:37:58.951392Z",
     "iopub.status.busy": "2025-03-09T19:37:58.950903Z",
     "iopub.status.idle": "2025-03-09T19:38:00.508976Z",
     "shell.execute_reply": "2025-03-09T19:38:00.508114Z"
    },
    "papermill": {
     "duration": 1.632644,
     "end_time": "2025-03-09T19:38:00.510334",
     "exception": false,
     "start_time": "2025-03-09T19:37:58.877690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250309_193758-5xpuhgh2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrun-small-long\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/adromashkina-hse/translation-de-en\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/adromashkina-hse/translation-de-en/runs/5xpuhgh2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/adromashkina-hse/translation-de-en/runs/5xpuhgh2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7aa7e91a2770>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"translation-de-en\", name=\"run-small-long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8668933e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:48.000623Z",
     "iopub.status.busy": "2025-03-11T14:05:48.000320Z",
     "iopub.status.idle": "2025-03-11T14:05:48.074494Z",
     "shell.execute_reply": "2025-03-11T14:05:48.073562Z",
     "shell.execute_reply.started": "2025-03-11T14:05:48.000600Z"
    },
    "papermill": {
     "duration": 0.170147,
     "end_time": "2025-03-09T19:38:00.730286",
     "exception": false,
     "start_time": "2025-03-09T19:38:00.560139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e50ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:48.076552Z",
     "iopub.status.busy": "2025-03-11T14:05:48.076171Z",
     "iopub.status.idle": "2025-03-11T14:05:48.093644Z",
     "shell.execute_reply": "2025-03-11T14:05:48.092788Z",
     "shell.execute_reply.started": "2025-03-11T14:05:48.076506Z"
    },
    "papermill": {
     "duration": 0.053815,
     "end_time": "2025-03-09T19:38:00.832152",
     "exception": false,
     "start_time": "2025-03-09T19:38:00.778337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return [line.strip().split() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5605935f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T19:38:00.927403Z",
     "iopub.status.busy": "2025-03-09T19:38:00.927111Z",
     "iopub.status.idle": "2025-03-09T19:38:00.930438Z",
     "shell.execute_reply": "2025-03-09T19:38:00.929585Z"
    },
    "papermill": {
     "duration": 0.05204,
     "end_time": "2025-03-09T19:38:00.931753",
     "exception": false,
     "start_time": "2025-03-09T19:38:00.879713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def write_file_part(file_old, file_new, length):\n",
    "#   old_file = ''.join(open(file_old).readlines()[:length])\n",
    "#   open(file_new, 'w').write(old_file)\n",
    "\n",
    "# data_folder = '/kaggle/input/en-german/data/'\n",
    "# texts_folder = '/kaggle/working/'\n",
    "# new_train_len = int(len(open(f'{data_folder}train.de-en.en').readlines()) * 0.1)\n",
    "# write_file_part(f'{data_folder}train.de-en.en', f'{texts_folder}train_0.1.de-en.en', new_train_len)\n",
    "# write_file_part(f'{data_folder}train.de-en.de', f'{texts_folder}train_0.1.de-en.de', new_train_len)\n",
    "\n",
    "# new_val_len = int(len(open(f'{data_folder}val.de-en.en').readlines()) * 0.1)\n",
    "# write_file_part(f'{data_folder}val.de-en.en', f'{texts_folder}val_0.1.de-en.en', new_val_len)\n",
    "# write_file_part(f'{data_folder}val.de-en.de', f'{texts_folder}val_0.1.de-en.de', new_val_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "416c86bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T19:38:01.029324Z",
     "iopub.status.busy": "2025-03-09T19:38:01.029079Z",
     "iopub.status.idle": "2025-03-09T19:38:01.032220Z",
     "shell.execute_reply": "2025-03-09T19:38:01.031498Z"
    },
    "papermill": {
     "duration": 0.051808,
     "end_time": "2025-03-09T19:38:01.033529",
     "exception": false,
     "start_time": "2025-03-09T19:38:00.981721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_src = load_data(\"/kaggle/working/train_0.1.de-en.de\")\n",
    "# train_tgt = load_data(\"/kaggle/working/train_0.1.de-en.en\")\n",
    "# val_src = load_data(\"/kaggle/working/val_0.1.de-en.de\")\n",
    "# val_tgt = load_data(\"/kaggle/working/val_0.1.de-en.en\")\n",
    "# test_data = load_data(\"/kaggle/input/en-german/data/test1.de-en.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22876851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:48.094768Z",
     "iopub.status.busy": "2025-03-11T14:05:48.094529Z",
     "iopub.status.idle": "2025-03-11T14:05:50.614591Z",
     "shell.execute_reply": "2025-03-11T14:05:50.613742Z",
     "shell.execute_reply.started": "2025-03-11T14:05:48.094748Z"
    },
    "papermill": {
     "duration": 2.249932,
     "end_time": "2025-03-09T19:38:03.330541",
     "exception": false,
     "start_time": "2025-03-09T19:38:01.080609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_src = load_data(\"/kaggle/input/en-german/data/train.de-en.de\")\n",
    "train_tgt = load_data(\"/kaggle/input/en-german/data/train.de-en.en\")\n",
    "val_src = load_data(\"/kaggle/input/en-german/data/val.de-en.de\")\n",
    "val_tgt = load_data(\"/kaggle/input/en-german/data/val.de-en.en\")\n",
    "test_data = load_data(\"/kaggle/input/en-german/data/test1.de-en.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a6b967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T19:38:03.427822Z",
     "iopub.status.busy": "2025-03-09T19:38:03.427534Z",
     "iopub.status.idle": "2025-03-09T19:38:03.431117Z",
     "shell.execute_reply": "2025-03-09T19:38:03.430415Z"
    },
    "papermill": {
     "duration": 0.052768,
     "end_time": "2025-03-09T19:38:03.432414",
     "exception": false,
     "start_time": "2025-03-09T19:38:03.379646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# all_src = train_src + val_src\n",
    "# all_tgt = train_tgt + val_tgt\n",
    "\n",
    "# data_pairs = list(zip(all_src, all_tgt))\n",
    "# random.shuffle(data_pairs)\n",
    "\n",
    "# train_size = int(0.3 * len(data_pairs))  \n",
    "# #val_size = len(data_pairs) - train_size  \n",
    "\n",
    "# # Ğ Ğ°Ğ·Ğ´ĞµĞ»ÑĞµĞ¼ Ğ½Ğ° train Ğ¸ val\n",
    "# train_data = data_pairs[:train_size]\n",
    "# val_data = data_pairs[train_size:int(1.5*train_size)]\n",
    "\n",
    "# # Ğ Ğ°Ğ·Ğ´ĞµĞ»ÑĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ½Ğ° src Ğ¸ tgt\n",
    "# train_src, train_tgt = zip(*train_data)\n",
    "# val_src, val_tgt = zip(*val_data)\n",
    "\n",
    "# # ĞŸÑ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ² ÑĞ¿Ğ¸ÑĞºĞ¸\n",
    "# train_src = list(train_src)\n",
    "# train_tgt = list(train_tgt)\n",
    "# val_src = list(val_src)\n",
    "# val_tgt = list(val_tgt)\n",
    "\n",
    "# # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…\n",
    "# print(f\"Train data size: {len(train_src)} -> {len(train_tgt)}\")\n",
    "# print(f\"Validation data size: {len(val_src)} -> {len(val_tgt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a89376",
   "metadata": {
    "papermill": {
     "duration": 0.04837,
     "end_time": "2025-03-09T19:38:03.535203",
     "exception": false,
     "start_time": "2025-03-09T19:38:03.486833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "=================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198dd62f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.615856Z",
     "iopub.status.busy": "2025-03-11T14:05:50.615544Z",
     "iopub.status.idle": "2025-03-11T14:05:50.625598Z",
     "shell.execute_reply": "2025-03-11T14:05:50.624713Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.615827Z"
    },
    "papermill": {
     "duration": 0.061994,
     "end_time": "2025-03-09T19:38:03.644663",
     "exception": false,
     "start_time": "2025-03-09T19:38:03.582669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _yield_tokens(data):\n",
    "    for sentence in data:\n",
    "        yield sentence\n",
    "\n",
    "\n",
    "def get_data(train_src, train_tgt, val_src, val_tgt, test_data):\n",
    "    src_lang = \"de\"\n",
    "    tgt_lang = \"en\"\n",
    "    \n",
    "    train_src = load_data(\"/kaggle/input/en-german/data/train.de-en.de\")\n",
    "    train_tgt = load_data(\"/kaggle/input/en-german/data/train.de-en.en\")\n",
    "    val_src = load_data(\"/kaggle/input/en-german/data/val.de-en.de\")\n",
    "    val_tgt = load_data(\"/kaggle/input/en-german/data/val.de-en.en\")\n",
    "    test_data = load_data(\"/kaggle/input/en-german/data/test1.de-en.de\")\n",
    "\n",
    "\n",
    "    special_symbols = {\n",
    "        \"<unk>\":0,\n",
    "        \"<pad>\":1,\n",
    "        \"<bos>\":2,\n",
    "        \"<eos>\":3\n",
    "    }\n",
    "\n",
    "    \n",
    "    src_vocab = build_vocab_from_iterator(\n",
    "        _yield_tokens(train_src),\n",
    "        min_freq=5,\n",
    "        specials=list(special_symbols.keys()),\n",
    "        special_first=True\n",
    "    )\n",
    "\n",
    "    tgt_vocab = build_vocab_from_iterator(\n",
    "        _yield_tokens(train_tgt),\n",
    "        min_freq=5,\n",
    "        specials=list(special_symbols.keys()),\n",
    "        special_first=True\n",
    "    )\n",
    "\n",
    "    src_vocab.set_default_index(special_symbols[\"<unk>\"])\n",
    "    tgt_vocab.set_default_index(special_symbols[\"<unk>\"])\n",
    "\n",
    "    def _seq_transform(*transforms):\n",
    "        def func(txt_input):\n",
    "            for transform in transforms:\n",
    "                txt_input = transform(txt_input)\n",
    "            return txt_input\n",
    "        return func\n",
    "\n",
    "\n",
    "    # Function to add BOS/EOS and create tensor for input sequence indices\n",
    "    def _tensor_transform(token_ids):\n",
    "        return torch.cat(\n",
    "            (torch.tensor([special_symbols[\"<bos>\"]]),\n",
    "             torch.tensor(token_ids),\n",
    "             torch.tensor([special_symbols[\"<eos>\"]]))\n",
    "        )\n",
    "\n",
    "    src_lang_transform = _seq_transform(src_vocab, _tensor_transform)\n",
    "    tgt_lang_transform = _seq_transform(tgt_vocab, _tensor_transform)\n",
    "\n",
    "\n",
    "    def _collate_fn(batch):\n",
    "        src_batch, tgt_batch = [], []\n",
    "        for src_sample, tgt_sample in batch:\n",
    "            #print(src_sample)\n",
    "            #print('---')\n",
    "            #print(tgt_sample)\n",
    "            src_batch.append(src_lang_transform(src_sample))\n",
    "            tgt_batch.append(tgt_lang_transform(tgt_sample))\n",
    "\n",
    "        src_batch = pad_sequence(src_batch, padding_value=special_symbols[\"<pad>\"])\n",
    "        tgt_batch = pad_sequence(tgt_batch, padding_value=special_symbols[\"<pad>\"])\n",
    "        return src_batch, tgt_batch\n",
    "    \n",
    "    BATCH_SIZE = 128\n",
    "    train_iterator = list(zip(train_src, train_tgt))\n",
    "    valid_iterator = list(zip(val_src, val_tgt))\n",
    "    train_dataloader = DataLoader(train_iterator, batch_size=BATCH_SIZE, collate_fn=_collate_fn)\n",
    "    valid_dataloader = DataLoader(valid_iterator, batch_size=BATCH_SIZE, collate_fn=_collate_fn)\n",
    "\n",
    "    return train_dataloader, valid_dataloader, src_vocab, tgt_vocab, src_lang_transform, tgt_lang_transform, special_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b882b4ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.626669Z",
     "iopub.status.busy": "2025-03-11T14:05:50.626431Z",
     "iopub.status.idle": "2025-03-11T14:05:50.644847Z",
     "shell.execute_reply": "2025-03-11T14:05:50.643998Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.626648Z"
    },
    "papermill": {
     "duration": 0.055929,
     "end_time": "2025-03-09T19:38:03.749228",
     "exception": false,
     "start_time": "2025-03-09T19:38:03.693299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_size,\n",
    "        dropout,\n",
    "        maxlen=128\n",
    "    ):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98dc01cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.647728Z",
     "iopub.status.busy": "2025-03-11T14:05:50.647429Z",
     "iopub.status.idle": "2025-03-11T14:05:50.658675Z",
     "shell.execute_reply": "2025-03-11T14:05:50.657768Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.647699Z"
    },
    "papermill": {
     "duration": 0.059388,
     "end_time": "2025-03-09T19:38:03.856216",
     "exception": false,
     "start_time": "2025-03-09T19:38:03.796828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Translator(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            embed_size,\n",
    "            num_heads,\n",
    "            src_vocab_size,\n",
    "            tgt_vocab_size,\n",
    "            dim_feedforward,\n",
    "            dropout\n",
    "        ):\n",
    "        super(Translator, self).__init__()\n",
    "\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, embed_size)\n",
    "\n",
    "        self.pos_enc = PositionalEncoding(embed_size, dropout)\n",
    "\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embed_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.ff = nn.Linear(embed_size, tgt_vocab_size)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src, trg, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
    "\n",
    "        src_emb = self.pos_enc(self.src_embedding(src))\n",
    "        tgt_emb = self.pos_enc(self.tgt_embedding(trg))\n",
    "\n",
    "        outs = self.transformer(\n",
    "            src_emb,\n",
    "            tgt_emb,\n",
    "            src_mask,\n",
    "            tgt_mask,\n",
    "            None,\n",
    "            src_padding_mask,\n",
    "            tgt_padding_mask,\n",
    "            memory_key_padding_mask\n",
    "        )\n",
    "\n",
    "        return self.ff(outs)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "\n",
    "        embed = self.src_embedding(src)\n",
    "\n",
    "        pos_enc = self.pos_enc(embed)\n",
    "\n",
    "        return self.transformer.encoder(pos_enc, src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        \n",
    "        embed = self.tgt_embedding(tgt)\n",
    "\n",
    "        pos_enc = self.pos_enc(embed)\n",
    "\n",
    "        return self.transformer.decoder(pos_enc, memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec9b0d9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.660083Z",
     "iopub.status.busy": "2025-03-11T14:05:50.659810Z",
     "iopub.status.idle": "2025-03-11T14:05:50.675439Z",
     "shell.execute_reply": "2025-03-11T14:05:50.674569Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.660055Z"
    },
    "papermill": {
     "duration": 0.056027,
     "end_time": "2025-03-09T19:38:03.963762",
     "exception": false,
     "start_time": "2025-03-09T19:38:03.907735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(size, device):\n",
    "    mask = (torch.triu(torch.ones((size, size), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c59157c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.676421Z",
     "iopub.status.busy": "2025-03-11T14:05:50.676119Z",
     "iopub.status.idle": "2025-03-11T14:05:50.688217Z",
     "shell.execute_reply": "2025-03-11T14:05:50.687365Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.676386Z"
    },
    "papermill": {
     "duration": 0.055668,
     "end_time": "2025-03-09T19:38:04.072866",
     "exception": false,
     "start_time": "2025-03-09T19:38:04.017198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_mask(src, tgt, pad_idx, device):\n",
    "\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == pad_idx).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == pad_idx).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d7db56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.689538Z",
     "iopub.status.busy": "2025-03-11T14:05:50.689142Z",
     "iopub.status.idle": "2025-03-11T14:05:50.703342Z",
     "shell.execute_reply": "2025-03-11T14:05:50.702463Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.689470Z"
    },
    "papermill": {
     "duration": 0.055022,
     "end_time": "2025-03-09T19:38:04.175147",
     "exception": false,
     "start_time": "2025-03-09T19:38:04.120125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_dl, loss_fn, optim, special_symbols):\n",
    "    losses = 0\n",
    "\n",
    "    model.train()\n",
    "    for src, tgt in tqdm(train_dl, ascii=True):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, special_symbols[\"<pad>\"], DEVICE)\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        optim.zero_grad()\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(list(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c54c4e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.704550Z",
     "iopub.status.busy": "2025-03-11T14:05:50.704121Z",
     "iopub.status.idle": "2025-03-11T14:05:50.716529Z",
     "shell.execute_reply": "2025-03-11T14:05:50.715649Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.704497Z"
    },
    "papermill": {
     "duration": 0.055284,
     "end_time": "2025-03-09T19:38:04.287271",
     "exception": false,
     "start_time": "2025-03-09T19:38:04.231987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, valid_dl, loss_fn, special_symbols):\n",
    "    losses = 0\n",
    "    model.eval()\n",
    "\n",
    "    for src, tgt in tqdm(valid_dl):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, special_symbols[\"<pad>\"], DEVICE)\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(list(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce11bb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:05:50.717624Z",
     "iopub.status.busy": "2025-03-11T14:05:50.717367Z",
     "iopub.status.idle": "2025-03-11T14:05:58.342657Z",
     "shell.execute_reply": "2025-03-11T14:05:58.341897Z",
     "shell.execute_reply.started": "2025-03-11T14:05:50.717604Z"
    },
    "papermill": {
     "duration": 9.419335,
     "end_time": "2025-03-09T19:38:13.757096",
     "exception": false,
     "start_time": "2025-03-09T19:38:04.337761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25379\n",
      "19057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl, src_vocab, tgt_vocab, src_lang_transform, tgt_lang_transform, special_symbols = get_data(train_src, train_tgt, val_src, val_tgt, test_data)\n",
    "\n",
    "src_vocab_size = len(src_vocab)\n",
    "print(src_vocab_size)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "print(tgt_vocab_size)\n",
    "    \n",
    "attn_heads=8\n",
    "enc_layers=3\n",
    "dec_layers=3\n",
    "                        \n",
    "embed_size=512           \n",
    "dim_feedforward=512\n",
    "dropout = 0.15\n",
    "    \n",
    "epochs = 50\n",
    "    \n",
    "model = Translator(\n",
    "        num_encoder_layers=enc_layers,\n",
    "        num_decoder_layers=dec_layers,\n",
    "        embed_size=embed_size,\n",
    "        num_heads=attn_heads,\n",
    "        src_vocab_size=src_vocab_size,\n",
    "        tgt_vocab_size=tgt_vocab_size,\n",
    "        dim_feedforward=dim_feedforward,\n",
    "        dropout=dropout\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=special_symbols[\"<pad>\"], label_smoothing=0.1)\n",
    "    \n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aeeb47e-ebd5-4c2a-a0eb-3a63b98419cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:06:06.718654Z",
     "iopub.status.busy": "2025-03-11T14:06:06.718170Z",
     "iopub.status.idle": "2025-03-11T14:06:08.789137Z",
     "shell.execute_reply": "2025-03-11T14:06:08.788313Z",
     "shell.execute_reply.started": "2025-03-11T14:06:06.718624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load('/kaggle/input/transformer_long/pytorch/default/1/transformer_long_3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ed32cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-09T19:38:13.851859Z",
     "iopub.status.busy": "2025-03-09T19:38:13.851461Z",
     "iopub.status.idle": "2025-03-10T05:20:20.422313Z",
     "shell.execute_reply": "2025-03-10T05:20:20.421435Z"
    },
    "papermill": {
     "duration": 34929.417425,
     "end_time": "2025-03-10T05:20:23.221491",
     "exception": false,
     "start_time": "2025-03-09T19:38:13.804066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1531 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "100%|##########| 1531/1531 [11:15<00:00,  2.26it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain loss: 6.347\n",
      "\tVal loss: 5.838\n",
      "\tEpoch time = 689.3 seconds\n",
      "\tETA = 33777.6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "\tTrain loss: 5.745\n",
      "\tVal loss: 5.526\n",
      "\tEpoch time = 697.2 seconds\n",
      "\tETA = 33466.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "\tTrain loss: 5.469\n",
      "\tVal loss: 5.223\n",
      "\tEpoch time = 696.9 seconds\n",
      "\tETA = 32753.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "\tTrain loss: 5.215\n",
      "\tVal loss: 4.965\n",
      "\tEpoch time = 697.3 seconds\n",
      "\tETA = 32077.6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "\tTrain loss: 4.991\n",
      "\tVal loss: 4.733\n",
      "\tEpoch time = 697.0 seconds\n",
      "\tETA = 31366.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "\tTrain loss: 4.784\n",
      "\tVal loss: 4.498\n",
      "\tEpoch time = 696.9 seconds\n",
      "\tETA = 30664.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "\tTrain loss: 4.592\n",
      "\tVal loss: 4.273\n",
      "\tEpoch time = 696.7 seconds\n",
      "\tETA = 29959.1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "\tTrain loss: 4.425\n",
      "\tVal loss: 4.096\n",
      "\tEpoch time = 697.1 seconds\n",
      "\tETA = 29280.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "\tTrain loss: 4.284\n",
      "\tVal loss: 3.971\n",
      "\tEpoch time = 697.1 seconds\n",
      "\tETA = 28581.1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "\tTrain loss: 4.166\n",
      "\tVal loss: 3.858\n",
      "\tEpoch time = 697.3 seconds\n",
      "\tETA = 27890.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\n",
      "\tTrain loss: 4.067\n",
      "\tVal loss: 3.767\n",
      "\tEpoch time = 696.8 seconds\n",
      "\tETA = 27176.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\n",
      "\tTrain loss: 3.981\n",
      "\tVal loss: 3.697\n",
      "\tEpoch time = 696.8 seconds\n",
      "\tETA = 26478.7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\n",
      "\tTrain loss: 3.906\n",
      "\tVal loss: 3.624\n",
      "\tEpoch time = 696.9 seconds\n",
      "\tETA = 25785.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\n",
      "\tTrain loss: 3.842\n",
      "\tVal loss: 3.577\n",
      "\tEpoch time = 697.4 seconds\n",
      "\tETA = 25105.1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\n",
      "\tTrain loss: 3.786\n",
      "\tVal loss: 3.535\n",
      "\tEpoch time = 697.2 seconds\n",
      "\tETA = 24402.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\n",
      "\tTrain loss: 3.736\n",
      "\tVal loss: 3.494\n",
      "\tEpoch time = 697.0 seconds\n",
      "\tETA = 23698.1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\n",
      "\tTrain loss: 3.693\n",
      "\tVal loss: 3.465\n",
      "\tEpoch time = 697.0 seconds\n",
      "\tETA = 23000.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\n",
      "\tTrain loss: 3.653\n",
      "\tVal loss: 3.432\n",
      "\tEpoch time = 697.2 seconds\n",
      "\tETA = 22311.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\n",
      "\tTrain loss: 3.618\n",
      "\tVal loss: 3.404\n",
      "\tEpoch time = 697.1 seconds\n",
      "\tETA = 21611.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n",
      "\tTrain loss: 3.585\n",
      "\tVal loss: 3.384\n",
      "\tEpoch time = 697.3 seconds\n",
      "\tETA = 20918.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\n",
      "\tTrain loss: 3.555\n",
      "\tVal loss: 3.366\n",
      "\tEpoch time = 697.6 seconds\n",
      "\tETA = 20230.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22\n",
      "\tTrain loss: 3.527\n",
      "\tVal loss: 3.340\n",
      "\tEpoch time = 697.7 seconds\n",
      "\tETA = 19535.4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23\n",
      "\tTrain loss: 3.502\n",
      "\tVal loss: 3.331\n",
      "\tEpoch time = 697.8 seconds\n",
      "\tETA = 18840.6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24\n",
      "\tTrain loss: 3.478\n",
      "\tVal loss: 3.311\n",
      "\tEpoch time = 697.2 seconds\n",
      "\tETA = 18128.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\n",
      "\tTrain loss: 3.456\n",
      "\tVal loss: 3.293\n",
      "\tEpoch time = 697.7 seconds\n",
      "\tETA = 17443.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26\n",
      "\tTrain loss: 3.435\n",
      "\tVal loss: 3.285\n",
      "\tEpoch time = 697.9 seconds\n",
      "\tETA = 16748.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27\n",
      "\tTrain loss: 3.416\n",
      "\tVal loss: 3.268\n",
      "\tEpoch time = 697.5 seconds\n",
      "\tETA = 16042.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28\n",
      "\tTrain loss: 3.398\n",
      "\tVal loss: 3.261\n",
      "\tEpoch time = 698.0 seconds\n",
      "\tETA = 15355.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29\n",
      "\tTrain loss: 3.380\n",
      "\tVal loss: 3.241\n",
      "\tEpoch time = 697.6 seconds\n",
      "\tETA = 14648.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\n",
      "\tTrain loss: 3.364\n",
      "\tVal loss: 3.235\n",
      "\tEpoch time = 697.3 seconds\n",
      "\tETA = 13946.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31\n",
      "\tTrain loss: 3.348\n",
      "\tVal loss: 3.231\n",
      "\tEpoch time = 697.9 seconds\n",
      "\tETA = 13259.4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32\n",
      "\tTrain loss: 3.334\n",
      "\tVal loss: 3.218\n",
      "\tEpoch time = 697.2 seconds\n",
      "\tETA = 12550.1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33\n",
      "\tTrain loss: 3.320\n",
      "\tVal loss: 3.210\n",
      "\tEpoch time = 697.2 seconds\n",
      "\tETA = 11852.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34\n",
      "\tTrain loss: 3.306\n",
      "\tVal loss: 3.204\n",
      "\tEpoch time = 697.6 seconds\n",
      "\tETA = 11161.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35\n",
      "\tTrain loss: 3.293\n",
      "\tVal loss: 3.195\n",
      "\tEpoch time = 698.2 seconds\n",
      "\tETA = 10472.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36\n",
      "\tTrain loss: 3.282\n",
      "\tVal loss: 3.187\n",
      "\tEpoch time = 697.4 seconds\n",
      "\tETA = 9763.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37\n",
      "\tTrain loss: 3.269\n",
      "\tVal loss: 3.176\n",
      "\tEpoch time = 697.4 seconds\n",
      "\tETA = 9066.7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38\n",
      "\tTrain loss: 3.257\n",
      "\tVal loss: 3.174\n",
      "\tEpoch time = 697.3 seconds\n",
      "\tETA = 8367.2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39\n",
      "\tTrain loss: 3.246\n",
      "\tVal loss: 3.165\n",
      "\tEpoch time = 698.0 seconds\n",
      "\tETA = 7678.4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40\n",
      "\tTrain loss: 3.236\n",
      "\tVal loss: 3.160\n",
      "\tEpoch time = 697.2 seconds\n",
      "\tETA = 6971.7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41\n",
      "\tTrain loss: 3.225\n",
      "\tVal loss: 3.156\n",
      "\tEpoch time = 697.1 seconds\n",
      "\tETA = 6273.6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42\n",
      "\tTrain loss: 3.217\n",
      "\tVal loss: 3.151\n",
      "\tEpoch time = 697.7 seconds\n",
      "\tETA = 5581.8 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43\n",
      "\tTrain loss: 3.206\n",
      "\tVal loss: 3.146\n",
      "\tEpoch time = 697.4 seconds\n",
      "\tETA = 4882.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44\n",
      "\tTrain loss: 3.198\n",
      "\tVal loss: 3.143\n",
      "\tEpoch time = 697.8 seconds\n",
      "\tETA = 4186.7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45\n",
      "\tTrain loss: 3.189\n",
      "\tVal loss: 3.139\n",
      "\tEpoch time = 697.7 seconds\n",
      "\tETA = 3488.3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:23<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46\n",
      "\tTrain loss: 3.180\n",
      "\tVal loss: 3.133\n",
      "\tEpoch time = 697.5 seconds\n",
      "\tETA = 2790.1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47\n",
      "\tTrain loss: 3.172\n",
      "\tVal loss: 3.129\n",
      "\tEpoch time = 697.6 seconds\n",
      "\tETA = 2092.9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48\n",
      "\tTrain loss: 3.164\n",
      "\tVal loss: 3.125\n",
      "\tEpoch time = 697.3 seconds\n",
      "\tETA = 1394.6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49\n",
      "\tTrain loss: 3.156\n",
      "\tVal loss: 3.122\n",
      "\tEpoch time = 697.5 seconds\n",
      "\tETA = 697.5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 1531/1531 [11:24<00:00,  2.24it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50\n",
      "\tTrain loss: 3.148\n",
      "\tVal loss: 3.115\n",
      "\tEpoch time = 698.0 seconds\n",
      "\tETA = 0.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, epoch in enumerate(range(1, epochs+1)):\n",
    "    start_time = time()\n",
    "    train_loss = train(model, train_dl, loss_fn, optim, special_symbols)\n",
    "    torch.save(model.state_dict(), 'transformer_long_3.pth')\n",
    "    epoch_time = time() - start_time\n",
    "    val_loss   = validate(model, valid_dl, loss_fn, special_symbols)\n",
    "    wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
    "    print(f\"Epoch: {epoch}\\n\\tTrain loss: {train_loss:.3f}\\n\\tVal loss: {val_loss:.3f}\\n\\tEpoch time = {epoch_time:.1f} seconds\\n\\tETA = {epoch_time*(epochs-idx-1):.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b94ec86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:06:19.421081Z",
     "iopub.status.busy": "2025-03-11T14:06:19.420776Z",
     "iopub.status.idle": "2025-03-11T14:06:19.428078Z",
     "shell.execute_reply": "2025-03-11T14:06:19.427381Z",
     "shell.execute_reply.started": "2025-03-11T14:06:19.421057Z"
    },
    "papermill": {
     "duration": 4.067703,
     "end_time": "2025-03-10T05:20:31.417062",
     "exception": false,
     "start_time": "2025-03-10T05:20:27.349359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol, end_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "\n",
    "    for _ in range(max_len-1):\n",
    "\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0), DEVICE).type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "\n",
    "        out = out.transpose(0, 1)\n",
    "\n",
    "        prob = model.ff(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == end_symbol:\n",
    "            break\n",
    "\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fdf4ad9-a312-4a50-a6b5-dc5822a677c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:41:20.475677Z",
     "iopub.status.busy": "2025-03-11T14:41:20.475390Z",
     "iopub.status.idle": "2025-03-11T14:41:20.482845Z",
     "shell.execute_reply": "2025-03-11T14:41:20.482074Z",
     "shell.execute_reply.started": "2025-03-11T14:41:20.475654Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(model, train_dl, valid_dl, src_vocab, tgt_vocab, src_lang_transform, tgt_lang_transform, special_symbols):\n",
    "    model.eval()\n",
    "\n",
    "    translated_sentences = []\n",
    "\n",
    "    for sentence in tqdm(test_data):\n",
    "       \n",
    "        encoded_src = src_lang_transform(sentence)\n",
    "        decoded_src = [src_vocab.lookup_tokens([token])[0] for token in encoded_src]\n",
    "        \n",
    "        unk_words = [word for word in sentence if word not in decoded_src]\n",
    "\n",
    "        src = encoded_src.view(-1, 1)\n",
    "        num_tokens = src.shape[0]\n",
    "        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "\n",
    "        tgt_tokens = greedy_decode(\n",
    "            model, src, src_mask, max_len=num_tokens+5, start_symbol=special_symbols[\"<bos>\"], end_symbol=special_symbols[\"<eos>\"]\n",
    "        ).flatten()\n",
    "\n",
    "        output_as_list = list(tgt_tokens.cpu().numpy())\n",
    "        output_list_words = tgt_vocab.lookup_tokens(output_as_list)\n",
    "\n",
    "        unk_index = 0\n",
    "        final_translation = []\n",
    "        for word in output_list_words:\n",
    "            if word == \"<bos>\" or word == \"<eos>\":\n",
    "                continue \n",
    "            if word == \"<unk>\" and unk_index < len(unk_words):\n",
    "                final_translation.append(unk_words[unk_index])  \n",
    "                unk_index += 1\n",
    "            else:\n",
    "                final_translation.append(word)\n",
    "\n",
    "        translated_sentences.append(\" \".join(final_translation).strip())\n",
    "\n",
    "    with open(\"translated_test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in translated_sentences:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    print(\"Translation complete. Saved to translated_test.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6f4116e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-11T14:41:23.061444Z",
     "iopub.status.busy": "2025-03-11T14:41:23.061078Z",
     "iopub.status.idle": "2025-03-11T14:45:26.869905Z",
     "shell.execute_reply": "2025-03-11T14:45:26.869062Z",
     "shell.execute_reply.started": "2025-03-11T14:41:23.061411Z"
    },
    "papermill": {
     "duration": 251.300669,
     "end_time": "2025-03-10T05:24:54.956336",
     "exception": false,
     "start_time": "2025-03-10T05:20:43.655667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2998/2998 [04:03<00:00, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation complete. Saved to translated_test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inference(model, train_dl, valid_dl, src_vocab, tgt_vocab, src_lang_transform, tgt_lang_transform, special_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d71a34d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T05:25:03.372541Z",
     "iopub.status.busy": "2025-03-10T05:25:03.372201Z",
     "iopub.status.idle": "2025-03-10T05:25:03.376202Z",
     "shell.execute_reply": "2025-03-10T05:25:03.375438Z"
    },
    "papermill": {
     "duration": 4.310053,
     "end_time": "2025-03-10T05:25:03.377604",
     "exception": false,
     "start_time": "2025-03-10T05:24:59.067551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def inference():\n",
    "\n",
    "#     train_dl, valid_dl, src_vocab, tgt_vocab, src_lang_transform, tgt_lang_transform, special_symbols = get_data(train_src, train_tgt, val_src, val_tgt, test_data)\n",
    "\n",
    "#     src_vocab_size = len(src_vocab)\n",
    "#     tgt_vocab_size = len(tgt_vocab)\n",
    "    \n",
    "#     attn_heads=8\n",
    "#     enc_layers=5\n",
    "#     dec_layers=5\n",
    "                        \n",
    "#     embed_size=512           \n",
    "#     dim_feedforward=512\n",
    "#     dropout = 0.3\n",
    " \n",
    "#     model = Translator(\n",
    "#         num_encoder_layers=enc_layers,\n",
    "#         num_decoder_layers=dec_layers,\n",
    "#         embed_size=embed_size,\n",
    "#         num_heads=attn_heads,\n",
    "#         src_vocab_size=src_vocab_size,\n",
    "#         tgt_vocab_size=tgt_vocab_size,\n",
    "#         dim_feedforward=dim_feedforward,\n",
    "#         dropout=dropout\n",
    "#     ).to(DEVICE)\n",
    "\n",
    "#     # Load in weights\n",
    "#     #model.load_state_dict(torch.load(opts.model_path))\n",
    "\n",
    "#     # Set to inference\n",
    "#     model.eval()\n",
    "\n",
    "#     # Accept input and keep translating until they quit\n",
    "#     while True:\n",
    "#         print(\"> \", end=\"\")\n",
    "\n",
    "#         sentence = input()\n",
    "\n",
    "#         # Convert to tokens\n",
    "#         src = src_transform(sentence).view(-1, 1)\n",
    "#         num_tokens = src.shape[0]\n",
    "\n",
    "#         src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "\n",
    "#         # Decode\n",
    "#         tgt_tokens = greedy_decode(\n",
    "#             model, src, src_mask, max_len=num_tokens+5, start_symbol=special_symbols[\"<bos>\"], end_symbol=special_symbols[\"<eos>\"]\n",
    "#         ).flatten()\n",
    "\n",
    "#         # Convert to list of tokens\n",
    "#         output_as_list = list(tgt_tokens.cpu().numpy())\n",
    "\n",
    "#         # Convert tokens to words\n",
    "#         output_list_words = tgt_vocab.lookup_tokens(output_as_list)\n",
    "\n",
    "#         # Remove special tokens and convert to string\n",
    "#         translation = \" \".join(output_list_words).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "\n",
    "#         print(translation)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6686625,
     "sourceId": 10776947,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6691306,
     "sourceId": 10783198,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 263742,
     "modelInstanceId": 242107,
     "sourceId": 282554,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35400.261472,
   "end_time": "2025-03-10T05:25:10.301484",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-09T19:35:10.040012",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
